# Data Warehouse and Analytics Project

Welcome to the **Data Warehouse and Analytics Project** repository! ğŸš€  
This project showcases a production-style data warehousing and analytics solution built on Databricks, using the Medallion Architecture (Bronze, Silver, Gold) to transform raw source data into trusted, analytics-ready datasets.

Designed as a portfolio and learning project, it demonstrates real-world data engineering best practices, including layered data modeling, data quality validation, and star-schema design optimised for business intelligence and reporting.

---
## ğŸ—ï¸ Data Architecture

The data architecture for this project follows Medallion Architecture **Bronze**, **Silver**, and **Gold** layers:

<!-- <img width="1401" height="911" alt="image" src="https://github.com/user-attachments/assets/0b593764-f14f-4908-be5d-01575fd43d8e" /> -->
<img width="5684" height="3564" alt="image" src="https://github.com/user-attachments/assets/321b38da-90a9-403f-bc1d-87cde309d3d0" />





1. **Bronze Layer**: Stores raw data as-is from the source systems. Data is ingested from CSV Files into SQL Server Database.
2. **Silver Layer**: This layer includes data cleansing, standardization, and normalization processes to prepare data for analysis.
3. **Gold Layer**: Houses business-ready data modeled into a star schema required for reporting and analytics.

---
## ğŸ“– Project Overview

This project involves:

1. **Data Architecture**: Designing a Modern Data Warehouse Using Medallion Architecture **Bronze**, **Silver**, and **Gold** layers.
2. **ETL Pipelines**: Extracting, transforming, and loading data from source systems into the warehouse.
3. **Data Modeling**: Developing fact and dimension tables optimized for analytical queries.
4. **Analytics & Reporting**: Creating SQL-based reports and dashboards for actionable insights.

ğŸ¯ This repository is an excellent resource for professionals and students looking to showcase expertise in:
- SQL Development
- Data Architect
- Data Engineering  
- ETL Pipeline Developer  
- Data Modeling  
- Data Analytics  

---


---

## ğŸš€ Project Requirements

### Building the Data Warehouse (Data Engineering)

#### Objective
Develop a modern data warehouse using SQL Server to consolidate sales data, enabling analytical reporting and informed decision-making.

#### Specifications
- **Data Sources**: Import data from two source systems (ERP and CRM) provided as CSV files.
- **Data Quality**: Cleanse and resolve data quality issues prior to analysis.
- **Integration**: Combine both sources into a single, user-friendly data model designed for analytical queries.
- **Scope**: Focus on the latest dataset only; historization of data is not required.
- **Documentation**: Provide clear documentation of the data model to support both business stakeholders and analytics teams.

---

### BI: Analytics & Reporting (Data Analysis)

#### Objective
Develop SQL-based analytics to deliver detailed insights into:
- **Customer Behavior**
- **Product Performance**
- **Sales Trends**

These insights empower stakeholders with key business metrics, enabling strategic decision-making.  

For more details, refer to [docs/requirements.md](docs/requirements.md).

## ğŸ“‚ Repository Structure
```
data-warehouse-project/
â”‚
â”œâ”€â”€ datasets/                           # Raw datasets used for the project (ERP and CRM data)
â”‚
â”œâ”€â”€ docs/                               # Project documentation and architecture details
â”‚   â”œâ”€â”€ etl.drawio                      # Draw.io file shows all different techniquies and methods of ETL
â”‚   â”œâ”€â”€ data_architecture.drawio        # Draw.io file shows the project's architecture
â”‚   â”œâ”€â”€ data_catalog.md                 # Catalog of datasets, including field descriptions and metadata
â”‚   â”œâ”€â”€ data_flow.drawio                # Draw.io file for the data flow diagram
â”‚   â”œâ”€â”€ data_models.drawio              # Draw.io file for data models (star schema)
â”‚   â”œâ”€â”€ naming-conventions.md           # Consistent naming guidelines for tables, columns, and files
â”‚
â”œâ”€â”€ scripts/                            # SQL scripts for ETL and transformations
â”‚   â”œâ”€â”€ bronze/                         # Scripts for extracting and loading raw data
â”‚   â”œâ”€â”€ silver/                         # Scripts for cleaning and transforming data
â”‚   â”œâ”€â”€ gold/                           # Scripts for creating analytical models
â”‚
â”œâ”€â”€ tests/                              # Test scripts and quality files
â”‚
â”œâ”€â”€ README.md                           # Project overview and instructions
â”œâ”€â”€ LICENSE                             # License information for the repository
â”œâ”€â”€ .gitignore                          # Files and directories to be ignored by Git
â””â”€â”€ requirements.txt                    # Dependencies and requirements for the project
```
---


## ğŸ‘¤ About Me

Iâ€™m Afeez Laguda, a Data Engineer / Analytics Engineer with strong hands-on experience building end-to-end data platforms on Databricks using the Medallion Architecture (Bronze, Silver, Gold).

I specialise in SQL-based data engineering, Delta Lake, dimensional modelling, and data quality frameworks, delivering analytics-ready datasets that power Power BI dashboards and business reporting.

This project reflects how I work in real production environments â€” transforming raw data into trusted Gold-layer models, enforcing data quality, and enabling clear, high-impact insights for stakeholders.

## â˜• Stay Connected
linkedIn : https://www.linkedin.com/in/afeez-laguda-7b2256150/
